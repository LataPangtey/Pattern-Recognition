{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ka386xGf2K0f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan  9 15:18:04 2024       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.147.05   Driver Version: 525.147.05   CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A16          Off  | 00000000:35:00.0 Off |                    0 |\n",
      "|  0%   43C    P8    13W /  62W |      8MiB / 15356MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  NVIDIA A16          Off  | 00000000:36:00.0 Off |                    0 |\n",
      "|  0%   72C    P0    58W /  62W |  14003MiB / 15356MiB |     91%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  NVIDIA A16          Off  | 00000000:37:00.0 Off |                    0 |\n",
      "|  0%   34C    P8    13W /  62W |      7MiB / 15356MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  NVIDIA A16          Off  | 00000000:38:00.0 Off |                    0 |\n",
      "|  0%   32C    P8    12W /  62W |      4MiB / 15356MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2596      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    0   N/A  N/A      2943      G   ...ome-remote-desktop-daemon        1MiB |\n",
      "|    0   N/A  N/A    290543      G   ...gnome-shell-portal-helper        1MiB |\n",
      "|    1   N/A  N/A      2596      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    1   N/A  N/A    528652      C   ...ubhi/anaconda3/bin/python    13996MiB |\n",
      "|    2   N/A  N/A      2596      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "|    3   N/A  N/A      2596      G   /usr/lib/xorg/Xorg                  4MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "gpu_info = !nvidia-smi\n",
    "gpu_info = '\\n'.join(gpu_info)\n",
    "if gpu_info.find('failed') >= 0:\n",
    "  print('Not connected to a GPU')\n",
    "else:\n",
    "  print(gpu_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "oWiwuZYK2K0h"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\"\n",
    "os.environ[\"XLA_FLAGS\"] = \"--xla_gpu_cuda_data_dir='/usr/lib/cuda'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "TcmVdKpl2K0h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ni4YlmLUSFHD",
    "outputId": "c48c002a-7d84-4c0d-a7a4-317a088bc9eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: simpletransformers in /home/lata/.local/lib/python3.10/site-packages (0.64.5)\n",
      "Requirement already satisfied: numpy in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (1.26.2)\n",
      "Requirement already satisfied: requests in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (4.66.1)\n",
      "Requirement already satisfied: regex in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (2023.12.25)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (4.36.1)\n",
      "Requirement already satisfied: datasets in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (2.16.0)\n",
      "Requirement already satisfied: scipy in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (1.11.4)\n",
      "Requirement already satisfied: scikit-learn in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (1.3.2)\n",
      "Requirement already satisfied: seqeval in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (1.2.2)\n",
      "Requirement already satisfied: tensorboard in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (2.15.1)\n",
      "Requirement already satisfied: tensorboardx in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (2.6.2.2)\n",
      "Requirement already satisfied: pandas in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (2.1.4)\n",
      "Requirement already satisfied: tokenizers in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (0.15.0)\n",
      "Requirement already satisfied: wandb>=0.10.32 in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (0.16.1)\n",
      "Requirement already satisfied: streamlit in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (1.29.0)\n",
      "Requirement already satisfied: sentencepiece in /home/lata/.local/lib/python3.10/site-packages (from simpletransformers) (0.1.99)\n",
      "Requirement already satisfied: filelock in /home/lata/.local/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/lata/.local/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.20.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/lata/.local/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers>=4.31.0->simpletransformers) (5.4.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/lata/.local/lib/python3.10/site-packages (from transformers>=4.31.0->simpletransformers) (0.4.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/lib/python3/dist-packages (from wandb>=0.10.32->simpletransformers) (8.0.3)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /home/lata/.local/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (3.1.40)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /home/lata/.local/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (5.9.7)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /home/lata/.local/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.39.1)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /home/lata/.local/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n",
      "Requirement already satisfied: setproctitle in /home/lata/.local/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /home/lata/.local/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (69.0.3)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /home/lata/.local/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /home/lata/.local/lib/python3.10/site-packages (from wandb>=0.10.32->simpletransformers) (4.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lata/.local/lib/python3.10/site-packages (from requests->simpletransformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->simpletransformers) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lata/.local/lib/python3.10/site-packages (from requests->simpletransformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->simpletransformers) (2020.6.20)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/lata/.local/lib/python3.10/site-packages (from datasets->simpletransformers) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /home/lata/.local/lib/python3.10/site-packages (from datasets->simpletransformers) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /home/lata/.local/lib/python3.10/site-packages (from datasets->simpletransformers) (0.3.7)\n",
      "Requirement already satisfied: xxhash in /home/lata/.local/lib/python3.10/site-packages (from datasets->simpletransformers) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /home/lata/.local/lib/python3.10/site-packages (from datasets->simpletransformers) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /home/lata/.local/lib/python3.10/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets->simpletransformers) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /home/lata/.local/lib/python3.10/site-packages (from datasets->simpletransformers) (3.9.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/lata/.local/lib/python3.10/site-packages (from pandas->simpletransformers) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas->simpletransformers) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/lata/.local/lib/python3.10/site-packages (from pandas->simpletransformers) (2023.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/lata/.local/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/lata/.local/lib/python3.10/site-packages (from scikit-learn->simpletransformers) (3.2.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /home/lata/.local/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.2.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit->simpletransformers) (1.4)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /home/lata/.local/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.3.2)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in /usr/lib/python3/dist-packages (from streamlit->simpletransformers) (4.6.4)\n",
      "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/lib/python3/dist-packages (from streamlit->simpletransformers) (9.0.1)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /home/lata/.local/lib/python3.10/site-packages (from streamlit->simpletransformers) (13.7.0)\n",
      "Requirement already satisfied: tenacity<9,>=8.1.0 in /home/lata/.local/lib/python3.10/site-packages (from streamlit->simpletransformers) (8.2.3)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /home/lata/.local/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.10.2)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /home/lata/.local/lib/python3.10/site-packages (from streamlit->simpletransformers) (4.9.0)\n",
      "Requirement already satisfied: tzlocal<6,>=1.1 in /home/lata/.local/lib/python3.10/site-packages (from streamlit->simpletransformers) (5.2)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /home/lata/.local/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.22.0)\n",
      "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /home/lata/.local/lib/python3.10/site-packages (from streamlit->simpletransformers) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /home/lata/.local/lib/python3.10/site-packages (from streamlit->simpletransformers) (6.4)\n",
      "Requirement already satisfied: watchdog>=2.1.5 in /home/lata/.local/lib/python3.10/site-packages (from streamlit->simpletransformers) (3.0.0)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/lata/.local/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.0.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /home/lata/.local/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.60.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/lata/.local/lib/python3.10/site-packages (from tensorboard->simpletransformers) (2.25.2)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /home/lata/.local/lib/python3.10/site-packages (from tensorboard->simpletransformers) (1.2.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/lata/.local/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.5.1)\n",
      "Requirement already satisfied: six>1.9 in /usr/lib/python3/dist-packages (from tensorboard->simpletransformers) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/lata/.local/lib/python3.10/site-packages (from tensorboard->simpletransformers) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/lata/.local/lib/python3.10/site-packages (from tensorboard->simpletransformers) (3.0.1)\n",
      "Requirement already satisfied: jinja2 in /home/lata/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /home/lata/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.20.0)\n",
      "Requirement already satisfied: toolz in /home/lata/.local/lib/python3.10/site-packages (from altair<6,>=4.0->streamlit->simpletransformers) (0.12.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/lata/.local/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/lata/.local/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/lata/.local/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/lata/.local/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/lata/.local/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /home/lata/.local/lib/python3.10/site-packages (from aiohttp->datasets->simpletransformers) (4.0.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/lata/.local/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.11)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/lata/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/lata/.local/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard->simpletransformers) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/lata/.local/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->simpletransformers) (1.3.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/lata/.local/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/lata/.local/lib/python3.10/site-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.17.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/lata/.local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (2.1.3)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/lata/.local/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.1)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/lata/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/lata/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.32.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/lata/.local/lib/python3.10/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.16.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/lata/.local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /home/lata/.local/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->simpletransformers) (0.5.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->simpletransformers) (3.2.0)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 15:18:09.385152: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-01-09 15:18:09.436438: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-09 15:18:09.436490: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-09 15:18:09.437975: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-09 15:18:09.448312: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-09 15:18:10.511882: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/lata/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install simpletransformers\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification,DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam,Nadam\n",
    "from datasets import Dataset, DatasetDict\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "from tensorflow.keras.layers import Dropout, Dense, Reshape, Bidirectional, GRU, GlobalMaxPooling1D,Flatten,Reshape,MultiHeadAttention,Layer,Activation, Multiply, Lambda, Permute\n",
    "\n",
    "\n",
    "from tensorflow.keras import Input, Model, regularizers\n",
    "#!pip install transformers==4.36.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qxcWzk402K0i"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "snHQ6VMa7orS"
   },
   "outputs": [],
   "source": [
    "# !pip install nlpaug\n",
    "# import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_tDblJx4PwOU"
   },
   "outputs": [],
   "source": [
    "# train = pd.read_csv(\"/content/rumoureval2019_train.csv\")\n",
    "# test = pd.read_csv(\"/content/rumoureval2019_test.csv\")\n",
    "# val = pd.read_csv(\"/content/rumoureval2019_val.csv\")\n",
    "# # print(train.shape)\n",
    "# # train.sample(5)\n",
    "\n",
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "model_checkpoint = \"roberta-base\"  # Use RoBERTa model\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PikuO3VXEorQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QIymWQt5n3Yq"
   },
   "outputs": [],
   "source": [
    "# null_values = train.isnull().sum()\n",
    "# print(\"Null values in each column:\\n\", null_values)\n",
    "# # Remove rows with null entries\n",
    "# train = train.dropna()\n",
    "\n",
    "\n",
    "# null_values = val.isnull().sum()\n",
    "# print(\"Null values in each column:\\n\", null_values)\n",
    "# # Remove rows with null entries\n",
    "# val = val.dropna()\n",
    "\n",
    "# null_values = test.isnull().sum()\n",
    "# print(\"Null values in each column:\\n\", null_values)\n",
    "# # Remove rows with null entries\n",
    "# test = val.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "lV4Opuidrlzl"
   },
   "outputs": [],
   "source": [
    "# print(\"Original labels:\\n\", train['label'].sample(5))\n",
    "\n",
    "# # Create a mapping dictionary for label conversion\n",
    "# label_mapping = {'support': 0, 'comment': 1, 'deny': 2, 'query': 3}\n",
    "\n",
    "# # Replace string labels with numerical values\n",
    "# train['label_number'] = train['label'].map(label_mapping)\n",
    "# val['label_number'] = val['label'].map(label_mapping)\n",
    "# test['label_number'] = test['label'].map(label_mapping)\n",
    "\n",
    "# # Display the updated DataFrame with numerical labels\n",
    "# print(\"\\nUpdated labels:\\n\", train['label_number'].sample(5))\n",
    "# train.to_csv(\"/content/rumoureval2019_train_modified.csv\", index=False)\n",
    "# val.to_csv(\"/content/rumoureval2019_val_modified.csv\", index=False)\n",
    "# test.to_csv(\"/content/rumoureval2019_test_modified.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XI2i1q04rpl0"
   },
   "outputs": [],
   "source": [
    "# val.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_8t1KaU_WhQE",
    "outputId": "ea809daa-fdfe-4da7-f507-1780fce5e5a6"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55912f071ecf4d9e9d9fa7bd5544d8a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19ca4d78cc6d4f8aa7aad03486e6fdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating valid split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23440d77e9f7428b993af72754f7f77f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'source_text', 'reply_text', 'label', 'label_number'],\n",
       "        num_rows: 4877\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['id', 'source_text', 'reply_text', 'label', 'label_number'],\n",
       "        num_rows: 1440\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'source_text', 'reply_text', 'label', 'label_number'],\n",
       "        num_rows: 1675\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into train, validation, and test sets\n",
    "# train_data, test_data = train_test_split(train ,test_size=0.2, random_state=42)\n",
    "\n",
    "# print(test_data.shape)\n",
    "# test_data.tail(5)\n",
    "# train_data, val_data  = train_test_split(train_data ,test_size=0.2, random_state=1, shuffle=False)\n",
    "# train_data.to_csv('train_clean.csv',index=False)\n",
    "# val_data.to_csv('val_clean.csv',index=False)\n",
    "# test_data.to_csv('test_clean.csv',index=False)\n",
    "\n",
    "dataset = load_dataset('csv', data_files={'train': './rumoureval2019_train_modified.csv','valid':'./rumoureval2019_val_modified.csv','test':'./rumoureval2019_test_modified.csv'})\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414,
     "referenced_widgets": [
      "43eaf6c6d2dc481c9f54a8e00b3822c9",
      "122003800fb5489c81836e893dac45b9",
      "2eb155c62de44794ac01bfa0696a9796",
      "11a2cc19ff384a8eaaa5082416320f16",
      "d2b7d1759e35498c880756cf937102ed",
      "1277ea9e402e4770a37a811bbca55487",
      "7c73d698e09d4887a896dd5f5b89ccf2",
      "14bd9bc013a7439594ab3720f7d28eaf",
      "d4d8bd4be3304bb9bce2738bb93fdc17",
      "95b9b970b3af4498b98aafa105fe38e1",
      "801b972f226f4c71a1fbbb67f728e5b2"
     ]
    },
    "id": "tzuc4whoA9eM",
    "outputId": "94bd22f1-062c-4663-d1ef-c859d8c41abf"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124e81cfbff54032881881899598f8cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4877 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb01aa6208084a0eafeff71e2d66b588",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc18de2aba914e30aba8dac8153338e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1675 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'source_text', 'reply_text', 'label', 'label_number', 'input_ids', 'attention_mask', 'token_type_ids'],\n",
      "        num_rows: 4877\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['id', 'source_text', 'reply_text', 'label', 'label_number', 'input_ids', 'attention_mask', 'token_type_ids'],\n",
      "        num_rows: 1440\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'source_text', 'reply_text', 'label', 'label_number', 'input_ids', 'attention_mask', 'token_type_ids'],\n",
      "        num_rows: 1675\n",
      "    })\n",
      "})\n",
      "Columns added by tokenizer: ['input_ids', 'attention_mask', 'token_type_ids']\n"
     ]
    }
   ],
   "source": [
    "model_checkpoint = \"roberta-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "def preprocess_function_source(records):\n",
    "    tokenized = tokenizer(records['source_text'], truncation=True,padding='max_length', return_token_type_ids=True, max_length=128)\n",
    "    return {\n",
    "        'input_ids': tokenized['input_ids'],\n",
    "        'attention_mask': tokenized['attention_mask'],\n",
    "        'token_type_ids': tokenized['token_type_ids']\n",
    "    }\n",
    "\n",
    "\n",
    "pre_tokenizer_columns_source = set(dataset[\"train\"].features)\n",
    "\n",
    "pre_tokenizer_columns_source\n",
    "\n",
    "encoded_dataset_source = dataset.map(preprocess_function_source, batched=True, )\n",
    "\n",
    "print(encoded_dataset_source)\n",
    "\n",
    "tokenizer_columns_source = list(set(encoded_dataset_source[\"train\"].features) - pre_tokenizer_columns_source)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Columns added by tokenizer:\", tokenizer_columns_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xomTB4mqX0Vf",
    "outputId": "051be827-5900-477c-bb24-b056333bf7b4"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db6184cfe25c40b4a3c67844a69e3a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4877 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed79e70a58649a5a2640b2b0540d3b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1440 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ce1c5f778b4a4e8b8627b7c7a87001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1675 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['id', 'source_text', 'reply_text', 'label', 'label_number', 'input_ids', 'attention_mask', 'token_type_ids'],\n",
      "        num_rows: 4877\n",
      "    })\n",
      "    valid: Dataset({\n",
      "        features: ['id', 'source_text', 'reply_text', 'label', 'label_number', 'input_ids', 'attention_mask', 'token_type_ids'],\n",
      "        num_rows: 1440\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['id', 'source_text', 'reply_text', 'label', 'label_number', 'input_ids', 'attention_mask', 'token_type_ids'],\n",
      "        num_rows: 1675\n",
      "    })\n",
      "})\n",
      "Columns added by tokenizer: ['input_ids', 'attention_mask', 'token_type_ids']\n"
     ]
    }
   ],
   "source": [
    "def preprocess_function_reply(records):\n",
    "    tokenized = tokenizer(records['reply_text'], truncation=True,padding='max_length', return_token_type_ids=True, max_length=128)\n",
    "    return {\n",
    "        'input_ids': tokenized['input_ids'],\n",
    "        'attention_mask': tokenized['attention_mask'],\n",
    "        'token_type_ids': tokenized['token_type_ids']\n",
    "    }\n",
    "\n",
    "\n",
    "pre_tokenizer_columns_reply = set(dataset[\"train\"].features)\n",
    "\n",
    "pre_tokenizer_columns_reply\n",
    "\n",
    "encoded_dataset_reply = dataset.map(preprocess_function_reply, batched=True, )\n",
    "\n",
    "print(encoded_dataset_reply)\n",
    "\n",
    "tokenizer_columns_reply = list(set(encoded_dataset_reply[\"train\"].features) - pre_tokenizer_columns_reply)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Columns added by tokenizer:\", tokenizer_columns_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jgD1S40eAfp",
    "outputId": "4c6ba931-67c8-49eb-afa5-31ea7a4288f1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nlpaug in /home/lata/.local/lib/python3.10/site-packages (1.1.11)\n",
      "Requirement already satisfied: numpy>=1.16.2 in /home/lata/.local/lib/python3.10/site-packages (from nlpaug) (1.26.2)\n",
      "Requirement already satisfied: pandas>=1.2.0 in /home/lata/.local/lib/python3.10/site-packages (from nlpaug) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.22.0 in /home/lata/.local/lib/python3.10/site-packages (from nlpaug) (2.31.0)\n",
      "Requirement already satisfied: gdown>=4.0.0 in /home/lata/.local/lib/python3.10/site-packages (from nlpaug) (4.7.1)\n",
      "Requirement already satisfied: filelock in /home/lata/.local/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (3.13.1)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from gdown>=4.0.0->nlpaug) (1.16.0)\n",
      "Requirement already satisfied: tqdm in /home/lata/.local/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (4.66.1)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/lata/.local/lib/python3.10/site-packages (from gdown>=4.0.0->nlpaug) (4.12.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/lata/.local/lib/python3.10/site-packages (from pandas>=1.2.0->nlpaug) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/lib/python3/dist-packages (from pandas>=1.2.0->nlpaug) (2022.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/lata/.local/lib/python3.10/site-packages (from pandas>=1.2.0->nlpaug) (2023.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/lata/.local/lib/python3.10/site-packages (from requests>=2.22.0->nlpaug) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.22.0->nlpaug) (3.3)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/lata/.local/lib/python3.10/site-packages (from requests>=2.22.0->nlpaug) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.22.0->nlpaug) (2020.6.20)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/lata/.local/lib/python3.10/site-packages (from beautifulsoup4->gdown>=4.0.0->nlpaug) (2.5)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /home/lata/.local/lib/python3.10/site-packages (from requests[socks]->gdown>=4.0.0->nlpaug) (1.7.1)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install nlpaug\n",
    "\n",
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"tf\")\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "t0wDEuj9SaxO"
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Assuming df is your DataFrame\n",
    "# class_counts = train['label'].value_counts()\n",
    "\n",
    "# print(\"Number of occurrences of each class:\")\n",
    "# print(class_counts)\n",
    "\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "max_length = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DsSgRUtZuE0z"
   },
   "outputs": [],
   "source": [
    "#source\n",
    "input_ids_train_source = np.array(encoded_dataset_source['train']['input_ids'])\n",
    "token_type_ids_train_source = np.array(encoded_dataset_source['train']['token_type_ids'])\n",
    "attention_mask_train_source = np.array(encoded_dataset_source['train']['attention_mask'])\n",
    "\n",
    "\n",
    "#reply\n",
    "input_ids_train_reply = np.array(encoded_dataset_reply['train']['input_ids'])\n",
    "token_type_ids_train_reply = np.array(encoded_dataset_reply['train']['token_type_ids'])\n",
    "attention_mask_train_reply = np.array(encoded_dataset_reply['train']['attention_mask'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "7ScH_ZHdsVmY"
   },
   "outputs": [],
   "source": [
    "#source\n",
    "input_ids_valid_source = np.array(encoded_dataset_source['valid']['input_ids'])\n",
    "token_type_ids_valid_source = np.array(encoded_dataset_source['valid']['token_type_ids'])\n",
    "attention_mask_valid_source = np.array(encoded_dataset_source['valid']['attention_mask'])\n",
    "\n",
    "#reply\n",
    "input_ids_valid_reply = np.array(encoded_dataset_reply['valid']['input_ids'])\n",
    "token_type_ids_valid_reply = np.array(encoded_dataset_reply['valid']['token_type_ids'])\n",
    "attention_mask_valid_reply = np.array(encoded_dataset_reply['valid']['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "ESUffFbNYGA1"
   },
   "outputs": [],
   "source": [
    "#source\n",
    "input_ids_test_source = np.array(encoded_dataset_source['test']['input_ids'])\n",
    "token_type_ids_test_source = np.array(encoded_dataset_source['test']['token_type_ids'])\n",
    "attention_mask_test_source = np.array(encoded_dataset_source['test']['attention_mask'])\n",
    "\n",
    "#reply\n",
    "input_ids_test_reply = np.array(encoded_dataset_reply['test']['input_ids'])\n",
    "token_type_ids_test_reply = np.array(encoded_dataset_reply['test']['token_type_ids'])\n",
    "attention_mask_test_reply = np.array(encoded_dataset_reply['test']['attention_mask'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 371,
     "referenced_widgets": [
      "8d7d6dbad25e4df7ab94f446b46307d2",
      "d7e447b410ee47fea591122ff2d0c497",
      "5f047266bcdf4a41bd6f3fe80cb38e03",
      "c9d091cea7e84b7091373468dfa654ed",
      "26a65d266b234077bcda7400cb34431a",
      "96e74621c130478c9e4641ee4a6c14d5",
      "4442d8fb3fba4e10a92a190208a6027c",
      "a08f13ebd4064db99cccebf69a5550bf",
      "5a8df37110d741b8b6ac3e8e4acf9209",
      "e190ffa64ee842f08272e2ed22f39611",
      "902f7898eb4b4feb99714a1e49fa070a",
      "8b20937252034cd3a4a1c2685af9bda3",
      "f26974f197a44d688143dd71eb1019e3",
      "2c164843ef0f492e9ef62734d84d6b1f",
      "7c70afbbff044df491df36f19d9a0970",
      "9ae54140172d4182bc877725f78e9d64",
      "5c19b855bdaf4307bad8f1c8126e6c9e",
      "266e992726d64d29b880a4d2d7b5f4fc",
      "a46d93c247284282a2b39ada9bbe604c",
      "e401c1e3a85b428cabe2a5d90842fdb8",
      "2e4000e7d1fe4832b3f816879544abbc",
      "9bc832bc4eb4403a9825ec941f6e9b9d",
      "3f9462352e9d418897d2661978c06a2c",
      "097faca8be3d4093979bc101c32b89bc",
      "83ac50d258e54371a5d1fcd55cd3168c",
      "4ecb9ee623a5424abccb2d91f8e065d7",
      "7ce14c02563d4b8185a4fa2cd18244f4",
      "051e5e2ec40d4c3ab009fb2e61ea5ec7",
      "f0834e5d3d154491991fdf111a8e1604",
      "994b011d50ea4bbfb0e8edade091a328",
      "9ec255222851461789a192ae3416c845",
      "255561010d8245ee93903706ade19da7",
      "a2a778cc97874b9eb021b4d0eaca2e2a",
      "0d3799346117440c817127a69bdb2936",
      "a5bc1bbbde9f456a98ae94fe2e0f2419",
      "d81035761da64e28a76ba4957a86fbe6",
      "a2643e24790149e1a4d72b45f894b60a",
      "388cdfe2d0b24536a8d9f7ca59753212",
      "ed95b9e3da6f4a6cb2e7292ecb1267f1",
      "d0077d9fc8434bdf9fbf4d5b6e206bf7",
      "fb818641fd6a4c63920b9431fd29dac5",
      "77baa7033ec24055a0ba7e04efaa7e6f",
      "4dbec91e4544476cae6edc0feea56dd6",
      "e1d5bd15188f4cd7a324dd41dc55300e"
     ]
    },
    "id": "jDYweQ_BfD2_",
    "outputId": "0e182a29-6e36-489f-873b-f3bb9e81a4e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 15:18:24.445987: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 12744 MB memory:  -> device: 0, name: NVIDIA A16, pci bus id: 0000:37:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
       "array([[  101,  1619,   102],\n",
       "       [  101, 15027,   102],\n",
       "       [  101,  9762,   102],\n",
       "       [  101,  7368,   102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
       "array([[0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(4, 3), dtype=int32, numpy=\n",
       "array([[1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1],\n",
       "       [1, 1, 1]], dtype=int32)>}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_checkpoint2 = \"bert-base-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint2)\n",
    "labels=  ['support', 'query', 'deny','comment']\n",
    "tokenized_labels=tokenizer(labels,\n",
    "          return_tensors='tf',\n",
    "          return_token_type_ids=True,truncation=True,padding='max_length',  max_length=3)\n",
    "tokenized_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118,
     "referenced_widgets": [
      "d2f37583aea94993bd44ebb914310aa1",
      "19af24aa67a14504b58640d9a8521db3",
      "58ab2086ba0d40f68a63bedb118fd5b3",
      "40e9ce82eff94521a5ce93050acf68fa",
      "e833704b51464864a1f316ed1e7a8212",
      "96c7e2ba96364cd6ab917102f94d0a72",
      "5d6387a0bc574ac893df523b80e28736",
      "5babae87e56843bcb998c1d9d1014a4a",
      "17f29d7a39a24fe8aacc5f73ca12dc32",
      "8f7c1364418e40b69d67b36d14e5bbd1",
      "b7c369b70ed84a24bc88ede97844defc"
     ]
    },
    "id": "Wrcaj_kbg394",
    "outputId": "f39172f3-d22b-4356-b197-232685c805ae"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "max_length = 128\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dropout, Dense, Reshape, Bidirectional, GRU, GlobalMaxPooling1D,Flatten,Reshape\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.optimizers import Nadam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.layers import Activation, Multiply, Lambda, Permute\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "# Define the BERT model\n",
    "#model_checkpoint = \"bert-base-cased\"\n",
    "model_checkpoint2 = \"bert-base-cased\"\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint2)\n",
    "\n",
    "# Get the BERT base model\n",
    "bert_model2 = model.bert\n",
    "\n",
    "from tensorflow.keras.layers import Layer\n",
    "\n",
    "class BERTWrapperLayer(Layer):\n",
    "    def __init__(self, bert_model, **kwargs):\n",
    "        super(BERTWrapperLayer, self).__init__(**kwargs)\n",
    "        self.bert_model = bert_model\n",
    "\n",
    "    def call(self, inputs, **kwargs):\n",
    "        input_ids, token_type_ids, attention_mask = inputs\n",
    "        bert_output = self.bert_model(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        return bert_output.last_hidden_state\n",
    "bert_last_hidden_state_labels = BERTWrapperLayer(bert_model2)([tokenized_labels['input_ids'],tokenized_labels['token_type_ids'], tokenized_labels[\"attention_mask\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "lm3kUFdfjqVJ"
   },
   "outputs": [],
   "source": [
    "arr1 = bert_last_hidden_state_labels\n",
    "arr2 = np.mean(arr1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o138XthZSVS8",
    "outputId": "a09104bb-acde-43e3-bd51-261e96411416"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 768)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "f8053bbfdf8342efaed9c8b7c3d12a79",
      "804ee798e26b4570b5a153dae816cbe3",
      "5c99477e24d749a09dec6f39cc4bb851",
      "672eea6acc894fec9efb55efb0ad421e",
      "7ece26d808584dc8991a0f35e649da87",
      "c537e6910b3540558e9f6c376be65d8c",
      "b2c7ca98624e48de8e8210efc899ac1a",
      "f7f0caff662b4046b0b4c7ce90cf6522",
      "9141467ff832403e98ea2d1dde434b77",
      "0b33790c443843d3a7cfa8b1220079fa",
      "9200e4dcf2af493d96c8f4e3ef9dc9ec"
     ]
    },
    "id": "jULU0DDvSrTP",
    "outputId": "9a0f4f20-2c7e-48dc-8f18-f8791abc4350"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFRobertaForSequenceClassification: ['roberta.embeddings.position_ids']\n",
      "- This IS expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFRobertaForSequenceClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFRobertaForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Pass your input through the BERT model wrapper\n",
    "input_ids_source = Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids_source\")\n",
    "token_type_ids_source = Input(shape=(max_length,), dtype=tf.int32, name=\"token_type_ids_source\")\n",
    "attention_mask_source = Input(shape=(max_length,), dtype=tf.int32, name=\"attention_mask_source\")\n",
    "input_ids_reply = Input(shape=(max_length,), dtype=tf.int32, name=\"input_ids_reply\")\n",
    "token_type_ids_reply = Input(shape=(max_length,), dtype=tf.int32, name=\"token_type_ids_reply\")\n",
    "attention_mask_reply = Input(shape=(max_length,), dtype=tf.int32, name=\"attention_mask_reply\")\n",
    "arr2_input = Input(shape=(4,768), dtype=tf.float32, name=\"arr2_input\")\n",
    "# Pass your input through the BERT model wrapper\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_checkpoint)\n",
    "roberta_model=model.roberta\n",
    "\n",
    "#deberta_pooler_output, deberta_last_hidden_state = DeBERTaWrapperLayer(deberta_model)([input_ids, attention_mask])\n",
    "roberta_last_hidden_state_source = BERTWrapperLayer(roberta_model)([input_ids_source,token_type_ids_source, attention_mask_source])\n",
    "roberta_last_hidden_state_reply = BERTWrapperLayer(roberta_model)([input_ids_reply,token_type_ids_reply, attention_mask_reply])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pbFEd7YfvVw1",
    "outputId": "d8b9889d-5f10-4693-d1a0-b7ccb250cffc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'bert_wrapper_layer_1')>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_last_hidden_state_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "Y2GBiNHPvdR_"
   },
   "outputs": [],
   "source": [
    "pooler_output_source = tf.reduce_mean(roberta_last_hidden_state_source, axis=1)\n",
    "pooler_output_reply = tf.reduce_mean(roberta_last_hidden_state_reply, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_7fFQ2rI8DFA",
    "outputId": "9b3d37d0-0c37-49eb-b6fb-34bcb68e50bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Dimension of source: KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), name='tf.__operators__.getitem/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem'\")\n",
      "Rest of the Dimensions of source: KerasTensor(type_spec=TensorSpec(shape=(None, 127, 768), dtype=tf.float32, name=None), name='tf.__operators__.getitem_1/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_1'\")\n",
      "First Dimension of reply: KerasTensor(type_spec=TensorSpec(shape=(None, 768), dtype=tf.float32, name=None), name='tf.__operators__.getitem_2/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_2'\")\n",
      "Rest of the Dimensions of reply: KerasTensor(type_spec=TensorSpec(shape=(None, 127, 768), dtype=tf.float32, name=None), name='tf.__operators__.getitem_3/strided_slice:0', description=\"created by layer 'tf.__operators__.getitem_3'\")\n"
     ]
    }
   ],
   "source": [
    "sliced_cls_source = roberta_last_hidden_state_source[:, 0]\n",
    "\n",
    "# Slice the rest of the dimensions\n",
    "cls_rest_of_dimension_source = roberta_last_hidden_state_source[:, 1:]\n",
    "\n",
    "# Print or use the sliced outputs\n",
    "print(\"First Dimension of source:\", sliced_cls_source)\n",
    "\n",
    "print(\"Rest of the Dimensions of source:\", cls_rest_of_dimension_source)\n",
    "\n",
    "\n",
    "sliced_cls_reply = roberta_last_hidden_state_reply[:, 0]\n",
    "\n",
    "# Slice the rest of the dimensions\n",
    "cls_rest_of_dimension_reply = roberta_last_hidden_state_reply[:, 1:]\n",
    "\n",
    "# Print or use the sliced outputs\n",
    "print(\"First Dimension of reply:\", sliced_cls_reply)\n",
    "\n",
    "print(\"Rest of the Dimensions of reply:\", cls_rest_of_dimension_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JX9FSzWy8qeD",
    "outputId": "53c2fdff-c042-4511-d2c9-28f1a62e8996"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf.math.abs')>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_cls = tf.abs(sliced_cls_source - sliced_cls_reply)\n",
    "difference_cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zn0F9RqKK7D6",
    "outputId": "41aea655-7298-4faf-e74f-7a547c948961"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 512) dtype=float32 (created by layer 'dense')>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalized_difference = tf.math.l2_normalize(difference_cls, axis=1)\n",
    "dense_layer1 = tf.keras.layers.Dense(units=512, activation='Softmax')\n",
    "# dense_layer2 = tf.keras.layers.Dense(units=256, activation='Softmax')\n",
    "\n",
    "# # Apply the dense layer to the normalized difference\n",
    "normalized_difference1 = dense_layer1(normalized_difference)\n",
    "# output2 = dense_layer2(output1)\n",
    "normalized_difference1\n",
    "# output2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "DUexPab1YZeL"
   },
   "outputs": [],
   "source": [
    "# layer = MultiHeadAttention(num_heads=2, key_dim=2)\n",
    "# cross_attention_reply = layer(roberta_last_hidden_state_reply, roberta_last_hidden_state_reply)\n",
    "# print(cross_attention_reply.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "9g8JvGJ4oJ1J"
   },
   "outputs": [],
   "source": [
    "# layer = MultiHeadAttention(num_heads=2, key_dim=2)\n",
    "# cross_attention_source = layer(roberta_last_hidden_state_reply, roberta_last_hidden_state_source)\n",
    "# print(cross_attention_source.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "Lcxg6vWgowcj"
   },
   "outputs": [],
   "source": [
    "# import tensorflow as tf\n",
    "\n",
    "# class CrossAttentionLayer(tf.keras.layers.Layer):\n",
    "#     def __init__(self, embed_size, num_heads):\n",
    "#         super(CrossAttentionLayer, self).__init__()\n",
    "#         self.num_heads = num_heads\n",
    "#         self.embed_size = embed_size\n",
    "\n",
    "#         # Query, Key, and Value weight matrices\n",
    "#         self.WQ = tf.keras.layers.Dense(embed_size)\n",
    "#         self.WK = tf.keras.layers.Dense(embed_size)\n",
    "#         self.WV = tf.keras.layers.Dense(embed_size)\n",
    "\n",
    "#         # Output weight matrix\n",
    "#         self.WO = tf.keras.layers.Dense(embed_size)\n",
    "\n",
    "#     def scaled_dot_product_attention(self, Q, K, V):\n",
    "#         matmul_qk = tf.matmul(Q, K, transpose_b=True)\n",
    "#         dk = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "#         scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "#         attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "#         output = tf.matmul(attention_weights, V)\n",
    "#         return output, attention_weights\n",
    "\n",
    "#     def split_heads(self, x, batch_size):\n",
    "#         x = tf.reshape(x, (batch_size, -1, self.num_heads, self.embed_size // self.num_heads))\n",
    "#         return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "#     def call(self, inputs):\n",
    "#         query, key, value = inputs\n",
    "\n",
    "#         batch_size = tf.shape(query)[0]\n",
    "\n",
    "#         # Linear projections\n",
    "#         query = self.WQ(query)\n",
    "#         key = self.WK(key)\n",
    "#         value = self.WV(value)\n",
    "\n",
    "#         # Split heads\n",
    "#         query = self.split_heads(query, batch_size)\n",
    "#         key = self.split_heads(key, batch_size)\n",
    "#         value = self.split_heads(value, batch_size)\n",
    "\n",
    "#         # Scaled Dot-Product Attention\n",
    "#         scaled_attention, attention_weights = self.scaled_dot_product_attention(query, key, value)\n",
    "\n",
    "#         # Merge heads\n",
    "#         scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
    "#         concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.embed_size))\n",
    "\n",
    "#         # Linear projection\n",
    "#         output = self.WO(concat_attention)\n",
    "\n",
    "#         return output, attention_weights\n",
    "\n",
    "# # Example usage\n",
    "# seq_len = 128\n",
    "# batch_size = 32\n",
    "# embed_size = 256\n",
    "# num_heads = 8\n",
    "\n",
    "# cross_attention_layer = CrossAttentionLayer(embed_size, num_heads)\n",
    "\n",
    "# # Dummy input tensors\n",
    "# input_query = roberta_last_hidden_state_source\n",
    "# input_key = roberta_last_hidden_state_reply\n",
    "# input_value = roberta_last_hidden_state_source\n",
    "\n",
    "# # Apply cross-attention\n",
    "# cross_attention_source_output, attention_weights = cross_attention_layer([input_query, input_key, input_value])\n",
    "\n",
    "# print(\"Input Query Shape:\", input_query.shape)\n",
    "# print(\"Output Shape:\", cross_attention_source_output.shape)\n",
    "# print(\"Attention Weights Shape:\", attention_weights.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9diwootLx8f1",
    "outputId": "5779624e-aac2-41ac-a410-38ec43a6596b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Query Shape: (None, 128, 768)\n",
      "Output Shape: [None, 128, 256]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CrossAttentionLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, embed_size, num_heads):\n",
    "        super(CrossAttentionLayer, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.embed_size = embed_size\n",
    "\n",
    "        # Query, Key, and Value weight matrices\n",
    "        self.WQS = tf.keras.layers.Dense(embed_size)\n",
    "        self.WKS = tf.keras.layers.Dense(embed_size)\n",
    "        self.WVS = tf.keras.layers.Dense(embed_size)\n",
    "\n",
    "        self.WQR = tf.keras.layers.Dense(embed_size)\n",
    "        self.WKR = tf.keras.layers.Dense(embed_size)\n",
    "        self.WVR = tf.keras.layers.Dense(embed_size)\n",
    "\n",
    "        # Output weight matrix\n",
    "        self.WOS = tf.keras.layers.Dense(embed_size)\n",
    "        self.WOR = tf.keras.layers.Dense(embed_size)\n",
    "\n",
    "    def scaled_dot_product_attention(self, Q, K, V):\n",
    "        matmul_qk = tf.matmul(Q, K, transpose_b=True)\n",
    "        dk = tf.cast(tf.shape(K)[-1], tf.float32)\n",
    "        scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "        attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
    "        output = tf.matmul(attention_weights, V)\n",
    "        return output, attention_weights\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.embed_size // self.num_heads))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, inputs):\n",
    "        source, reply = inputs\n",
    "\n",
    "        query_s = source\n",
    "        query_r = reply\n",
    "\n",
    "        value_s = source\n",
    "        value_r = reply\n",
    "\n",
    "        key_s = reply\n",
    "        key_r = source\n",
    "\n",
    "        batch_size = tf.shape(query_s)[0]\n",
    "\n",
    "        # Linear projections\n",
    "        query_s = self.WQS(query_s)\n",
    "        key_s = self.WKS(key_s)\n",
    "        value_s = self.WVS(value_s)\n",
    "\n",
    "        query_r = self.WQR(query_r)\n",
    "        key_r = self.WKR(key_r)\n",
    "        value_r = self.WVR(value_r)\n",
    "\n",
    "        # Split heads\n",
    "        query_s = self.split_heads(query_s, batch_size)\n",
    "        key_s = self.split_heads(key_s, batch_size)\n",
    "        value_s = self.split_heads(value_s, batch_size)\n",
    "\n",
    "        query_r = self.split_heads(query_r, batch_size)\n",
    "        key_r = self.split_heads(key_r, batch_size)\n",
    "        value_r = self.split_heads(value_r, batch_size)\n",
    "\n",
    "        # Scaled Dot-Product Attention\n",
    "        scaled_attention_s, attention_weights_s = self.scaled_dot_product_attention(query_s, key_s, value_s)\n",
    "        #print(scaled_attention_s)\n",
    "        scaled_attention_r, attention_weights_r = self.scaled_dot_product_attention(query_r, key_r, value_r)\n",
    "\n",
    "        # Merge heads\n",
    "        scaled_attention_s = tf.transpose(scaled_attention_s, perm=[0, 2, 1, 3])\n",
    "        #print(scaled_attention_s)\n",
    "        concat_attention_s = tf.reshape(scaled_attention_s, (batch_size, seq_len, self.embed_size))\n",
    "        #print(concat_attention_s )\n",
    "\n",
    "        scaled_attention_r = tf.transpose(scaled_attention_r, perm=[0, 2, 1, 3])\n",
    "        concat_attention_r = tf.reshape(scaled_attention_r, (batch_size, seq_len, self.embed_size))\n",
    "\n",
    "        # Linear projection\n",
    "        output_s = self.WOS(concat_attention_s)\n",
    "        output_r = self.WOR(concat_attention_r)\n",
    "\n",
    "        return output_s, output_r\n",
    "\n",
    "# Example usage\n",
    "seq_len = 128\n",
    "batch_size = 32\n",
    "embed_size = 256\n",
    "num_heads = 8\n",
    "\n",
    "cross_attention_layer = CrossAttentionLayer(embed_size, num_heads)\n",
    "\n",
    "# Dummy input tensors\n",
    "input_query = roberta_last_hidden_state_reply\n",
    "input_key = roberta_last_hidden_state_source\n",
    "input_value = roberta_last_hidden_state_reply\n",
    "\n",
    "# Apply cross-attention\n",
    "cross_attention_source_output, cross_attention_reply_output = cross_attention_layer([roberta_last_hidden_state_source, roberta_last_hidden_state_reply])\n",
    "\n",
    "print(\"Input Query Shape:\", input_query.shape)\n",
    "print(\"Output Shape:\", cross_attention_reply_output.shape.as_list())\n",
    "#print(\"Attention Weights Shape:\", attention_weights.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "QKwI1OThyEJL"
   },
   "outputs": [],
   "source": [
    "#word attention on source\n",
    "word_embeddings = cross_attention_source_output\n",
    "\n",
    "# Apply word-level attention\n",
    "word_attention_scores = Dense(1, activation='relu')(word_embeddings)\n",
    "word_attention_scores\n",
    "word_attention_scores = Reshape((-1,))(word_attention_scores)\n",
    "word_attention_weights = Activation('softmax')(word_attention_scores)\n",
    "word_attention_weights = Reshape((-1, 1))(word_attention_weights)\n",
    "\n",
    "# Tile the attention weights to match the dimensions of word_embeddings\n",
    "word_attention_weights = Lambda(lambda x: tf.tile(x, [1, 1, 256]))(word_attention_weights)\n",
    "\n",
    "# Apply element-wise multiplication between word embeddings and attention weights\n",
    "word_attention = Multiply()([word_embeddings, word_attention_weights])\n",
    "\n",
    "# Sum up the word-level representations\n",
    "word_attention_sum_source = Lambda(lambda x: tf.reduce_sum(x, axis=1))(word_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "fND8NcyByJxz"
   },
   "outputs": [],
   "source": [
    "#word attention on reply\n",
    "word_embeddings = cross_attention_reply_output\n",
    "\n",
    "# Apply word-level attention\n",
    "word_attention_scores = Dense(1, activation='relu')(word_embeddings)\n",
    "word_attention_scores\n",
    "word_attention_scores = Reshape((-1,))(word_attention_scores)\n",
    "word_attention_weights = Activation('softmax')(word_attention_scores)\n",
    "word_attention_weights = Reshape((-1, 1))(word_attention_weights)\n",
    "\n",
    "# Tile the attention weights to match the dimensions of word_embeddings\n",
    "word_attention_weights = Lambda(lambda x: tf.tile(x, [1, 1, 256]))(word_attention_weights)\n",
    "\n",
    "# Apply element-wise multiplication between word embeddings and attention weights\n",
    "word_attention = Multiply()([word_embeddings, word_attention_weights])\n",
    "\n",
    "# Sum up the word-level representations\n",
    "word_attention_sum_reply = Lambda(lambda x: tf.reduce_sum(x, axis=1))(word_attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0FtMTjQs2rJs",
    "outputId": "f61d0398-c297-4aeb-a70a-6f29150fb2a7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'lambda_3')>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_attention_sum_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ogMHqoKjyLyE"
   },
   "outputs": [],
   "source": [
    "#concat word attentions with embeddings difference\n",
    "combined_representation_cross_attention_embedding_diff = tf.concat([word_attention_sum_source, word_attention_sum_reply,normalized_difference1], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1O-Lu6ozyzAs",
    "outputId": "7c49d8f1-0e66-4326-c865-d64c6b80c5eb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1024) dtype=float32 (created by layer 'tf.concat')>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_representation_cross_attention_embedding_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Ok7jqFLJ8aKq"
   },
   "outputs": [],
   "source": [
    "# def compute_fitness(agent, train_X, test_X, train_Y, test_Y, weight_acc=0.9, dims=None):\n",
    "#     # compute a basic fitness measure\n",
    "#     if(weight_acc == None):\n",
    "#         weight_acc = 0.99\n",
    "#     weight_feat = 1 - weight_acc\n",
    "\n",
    "#     if dims != None:\n",
    "#         num_features = dims\n",
    "#     else:\n",
    "#         num_features = agent.shape[0]\n",
    "\n",
    "#     acc = compute_accuracy(agent, train_X, test_X, train_Y, test_Y)\n",
    "#     feat = (num_features - np.sum(agent))/num_features\n",
    "\n",
    "#     fitness = weight_acc * acc + weight_feat * feat\n",
    "\n",
    "#     return fitness, acc\n",
    "# def AbSCA(num_agents, max_iter, train_data, train_label, obj_function=compute_fitness, trans_func_shape='s'):\n",
    "\n",
    "#     short_name = 'SCA'\n",
    "#     agent_name = 'Agent'\n",
    "#     train_data, train_label = np.array(train_data), np.array(train_label)\n",
    "#     num_features = train_data.shape[1]\n",
    "#     trans_function = get_trans_function(trans_func_shape)\n",
    "\n",
    "#     # setting up the objectives\n",
    "#     weight_acc = None\n",
    "#     if(obj_function == compute_fitness):\n",
    "#         weight_acc = 0.99\n",
    "#     obj = (obj_function, weight_acc)\n",
    "#     # compute_accuracy is just compute_fitness with accuracy weight as 1\n",
    "#     compute_accuracy = (compute_fitness, 1)\n",
    "\n",
    "#     # initialize agents and Leader (the agent with the max fitness)\n",
    "#     population = initialize(num_agents, num_features)\n",
    "#     fitness = np.zeros(num_agents)\n",
    "#     accuracy = np.zeros(num_agents)\n",
    "#     Leader_agent = np.zeros((1, num_features))\n",
    "#     Leader_fitness = float(\"-inf\")\n",
    "#     Leader_accuracy = float(\"-inf\")\n",
    "\n",
    "#     # initialize data class\n",
    "#     data = Data()\n",
    "#     data.train_X, data.val_X, data.train_Y, data.val_Y = train_test_split(\n",
    "#         train_data, train_label, shuffle=False, test_size=0.2)\n",
    "\n",
    "#     # create a solution object\n",
    "#     solution = Solution()\n",
    "#     solution.num_agents = num_agents\n",
    "#     solution.max_iter = max_iter\n",
    "#     solution.num_features = num_features\n",
    "#     solution.obj_function = obj_function\n",
    "\n",
    "#     # rank initial population\n",
    "#     population, fitness, accs = sort_agents(population, obj, data)\n",
    "#     Leader_agent = population[0].copy()\n",
    "#     Leader_fitness = fitness[0].copy()\n",
    "\n",
    "#     # start timer\n",
    "#     start_time = time.time()\n",
    "\n",
    "#     # Eq. (3.4)\n",
    "#     a = 3\n",
    "\n",
    "#     for iter_no in range(max_iter):\n",
    "#         print('\\n================================================================================')\n",
    "#         print('                          Iteration - {}'.format(iter_no+1))\n",
    "#         print('================================================================================\\n')\n",
    "\n",
    "#         # Eq. (3.4)\n",
    "#         r1 = a-iter_no*((a)/max_iter)  # r1 decreases linearly from a to 0\n",
    "\n",
    "#         # update the Position of search agents\n",
    "#         for i in range(num_agents):\n",
    "#             for j in range(num_features):\n",
    "\n",
    "#                 # update r2, r3, and r4 for Eq. (3.3)\n",
    "#                 r2 = (2 * np.pi) * np.random.random()\n",
    "#                 r3 = 2 * np.random.random()\n",
    "#                 r4 = np.random.random()\n",
    "\n",
    "#                 # Eq. (3.3)\n",
    "#                 if r4 < 0.5:\n",
    "#                     # Eq. (3.1)\n",
    "#                     population[i][j] = population[i][j] + (r1 * np.sin(r2) * abs(r3 * Leader_agent[j] - population[i][j]))\n",
    "#                 else:\n",
    "#                     # Eq. (3.2)\n",
    "#                     population[i][j] = population[i][j] + (r1 * np.cos(r2) * abs(r3 * Leader_agent[j] - population[i][j]))\n",
    "\n",
    "#                 temp = population[i][j].copy()\n",
    "#                 temp = trans_function(temp)\n",
    "#                 if temp > np.random.random():\n",
    "#                     population[i][j] = 1\n",
    "#                 else:\n",
    "#                     population[i][j] = 0\n",
    "\n",
    "#             # local search on every agent\n",
    "#             print(f'\\n******** Local Search on Agent {i+1} of Iteration {iter_no+1} ********\\n')\n",
    "\n",
    "#             agent = population[i].copy()\n",
    "#             agentFit, agentAcc = compute_fitness(agent, data.train_X, data.val_X, data.train_Y, data.val_Y, weight_acc=0.99)\n",
    "\n",
    "#             print(f'Initial fitness = {agentFit} | Initial accuracy = {agentAcc} | Nos of features = {int(np.sum(agent))}\\n')\n",
    "\n",
    "#             final_agent = adaptivebetaHC(agent, agentFit, agentAcc, data.train_X, data.val_X, data.train_Y, data.val_Y)\n",
    "\n",
    "#             population[i] = final_agent.copy()\n",
    "\n",
    "#         # update final information\n",
    "#         population, fitness, accs = sort_agents(population, obj, data)\n",
    "#         display(population, fitness, accs, agent_name)\n",
    "\n",
    "#         if fitness[0] > Leader_fitness:\n",
    "#             Leader_agent = population[0].copy()\n",
    "#             Leader_fitness = fitness[0].copy()\n",
    "\n",
    "#     # compute final accuracy\n",
    "#     Leader_agent, _, Leader_accuracy = sort_agents(Leader_agent, compute_accuracy, data)\n",
    "#     population, _, accuracy = sort_agents(population, compute_accuracy, data)\n",
    "\n",
    "#     print('\\n================================================================================')\n",
    "#     print('                                    Final Result                                  ')\n",
    "#     print('================================================================================\\n')\n",
    "#     print('Leader ' + agent_name +\n",
    "#           ' Dimension : {}'.format(int(np.sum(Leader_agent))))\n",
    "#     print('Leader ' + agent_name + ' Fitness : {}'.format(Leader_fitness))\n",
    "#     print('Leader ' + agent_name +\n",
    "#           ' Classification Accuracy : {}'.format(Leader_accuracy))\n",
    "#     print('\\n================================================================================\\n')\n",
    "\n",
    "#     # stop timer\n",
    "#     end_time = time.time()\n",
    "#     exec_time = end_time - start_time\n",
    "\n",
    "#     # update attributes of solution\n",
    "#     solution.best_agent = Leader_agent\n",
    "#     solution.best_fitness = Leader_fitness\n",
    "#     solution.best_accuracy = Leader_accuracy\n",
    "#     solution.final_particles = population\n",
    "#     solution.final_fitness = fitness\n",
    "#     solution.final_accuracy = accuracy\n",
    "#     solution.execution_time = exec_time\n",
    "\n",
    "#     return solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "n48H-kXZ8UGr"
   },
   "outputs": [],
   "source": [
    "# soln_AbSCA = AbSCA(num_agents=1, max_iter=1, train_data=combined_representation_cross_attention_embedding_diff, train_label=train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "EC7u8LFOyqZC"
   },
   "outputs": [],
   "source": [
    "# Add BiGRU layers for word-level attention\n",
    "gru_units = 64\n",
    "dropout_rate = 0.2\n",
    "\n",
    "output = Reshape((-1, gru_units))(combined_representation_cross_attention_embedding_diff)\n",
    "output = Bidirectional(GRU(gru_units, return_sequences=True))(output)\n",
    "output = Dropout(dropout_rate)(output)\n",
    "output = Bidirectional(GRU(gru_units, kernel_regularizer=regularizers.l2(0.01), return_sequences=True))(output)\n",
    "output = Dropout(dropout_rate)(output)\n",
    "\n",
    "# Apply sentence-level attention\n",
    "sentence_attention_scores = Dense(1, activation='relu')(output)\n",
    "sentence_attention_scores = Reshape((-1,))(sentence_attention_scores)\n",
    "sentence_attention_weights = Activation('softmax')(sentence_attention_scores)\n",
    "sentence_attention_weights = Reshape((-1, 1))(sentence_attention_weights)\n",
    "\n",
    "# Tile the attention weights to match the dimensions of output\n",
    "sentence_attention_weights = Lambda(lambda x: tf.tile(x, [1, 1, 2 * gru_units]))(sentence_attention_weights)\n",
    "\n",
    "# Apply element-wise multiplication between output and attention weights\n",
    "sentence_attention = Multiply()([output, sentence_attention_weights])\n",
    "\n",
    "# Sum up the sentence-level representations\n",
    "sentence_attention_sum = Lambda(lambda x: tf.reduce_sum(x, axis=1))(sentence_attention)\n",
    "\n",
    "# Apply global max pooling to capture the most important features\n",
    "sentence_attention_pooling = GlobalMaxPooling1D()(sentence_attention)\n",
    "\n",
    "combined_representation = tf.concat([sentence_attention_sum, sentence_attention_pooling], axis=1)\n",
    "flat_labels=Flatten()(arr2_input)\n",
    "dense_layer = tf.keras.layers.Dense(256, activation='relu')(flat_labels)\n",
    "model1 = Model(inputs= [input_ids_source,token_type_ids_source,attention_mask_source,input_ids_reply,token_type_ids_reply,attention_mask_reply],outputs=[combined_representation])\n",
    "dense_layer\n",
    "dot_product=tf.keras.layers.Dot(axes=1)([model1.output, dense_layer])\n",
    "#dot_product = tf.matmul(modelctR, dense_layer, transpose_b=True)\n",
    "\n",
    "# Add dropout regularization after the hierarchical attention layer\n",
    "#combined_representation = tf.concat([model1.output,v_p_s,v_neg_s,v_neu_s,v_p_r,v_neg_r,v_neu_r,clip_source_text,clip_reply_text,dot_product], axis=1)\n",
    "combined_representation = tf.concat([model1.output,dot_product], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KTKV1_h4Uzlr",
    "outputId": "6a23ff9a-1f04-45ab-c55c-474c9d750bd8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 1) dtype=float32 (created by layer 'dot')>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dot_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LB7rTJ-9UhsB",
    "outputId": "73c3966c-fd87-47bb-c87a-be6329a5fc26"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 256) dtype=float32 (created by layer 'tf.concat_1')>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "tXcxF3sr8c1J"
   },
   "outputs": [],
   "source": [
    "output = Dropout(dropout_rate)(combined_representation)\n",
    "\n",
    "# Add the final dense layer\n",
    "output_units = 4\n",
    "output1 = Dense(output_units, activation=\"softmax\")(output)\n",
    "output = BatchNormalization()(output)\n",
    "# Create a new model with the modified architecture\n",
    "#modified_model = Model(inputs=[model1.input,v_p_s,v_neg_s,v_neu_s,v_p_r,v_neg_r,v_neu_r,clip_source_text,clip_reply_text,arr2_input], outputs=output1)\n",
    "modified_model = Model(inputs=[model1.input,arr2_input], outputs=output1)\n",
    "\n",
    "# Define the optimizer\n",
    "learning_rate = 2e-5\n",
    "optimizer = Nadam(learning_rate=learning_rate)\n",
    "\n",
    "# Define the loss function\n",
    "loss = SparseCategoricalCrossentropy(from_logits=False)\n",
    "#CategoricalCrossentropy\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "T7FHKgb4xLIH"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "modified_model.compile(optimizer=optimizer, loss=loss, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fn8FKzhMcw_v",
    "outputId": "394a1ba3-986c-454b-af3c-64be5b53b6d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1440, 4, 768)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "replicated_array_train = np.tile(arr2, (len(encoded_dataset_reply[\"train\"]), 1,1))\n",
    "replicated_array_val = np.tile(arr2, (len(encoded_dataset_reply[\"valid\"]), 1,1))\n",
    "replicated_array_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dgAnsOM5xOjT",
    "outputId": "d0a0cd4b-57fc-4b20-c420-e64ab74f77a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "610/610 [==============================] - ETA: 0s - loss: 2.5748 - accuracy: 0.7519\n",
      "Epoch 1: val_accuracy improved from -inf to 0.81597, saving model to best_weights\n",
      "INFO:tensorflow:Assets written to: best_weights/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_weights/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610/610 [==============================] - 560s 919ms/step - loss: 2.5748 - accuracy: 0.7519 - val_loss: 2.2617 - val_accuracy: 0.8160\n",
      "Epoch 2/10\n",
      "610/610 [==============================] - ETA: 0s - loss: 2.1672 - accuracy: 0.7841\n",
      "Epoch 2: val_accuracy did not improve from 0.81597\n",
      "610/610 [==============================] - 527s 863ms/step - loss: 2.1672 - accuracy: 0.7841 - val_loss: 1.9587 - val_accuracy: 0.8139\n",
      "Epoch 3/10\n",
      "610/610 [==============================] - ETA: 0s - loss: 1.8001 - accuracy: 0.8245\n",
      "Epoch 3: val_accuracy did not improve from 0.81597\n",
      "610/610 [==============================] - 526s 862ms/step - loss: 1.8001 - accuracy: 0.8245 - val_loss: 1.8296 - val_accuracy: 0.7458\n",
      "Epoch 4/10\n",
      "610/610 [==============================] - ETA: 0s - loss: 1.4904 - accuracy: 0.8559\n",
      "Epoch 4: val_accuracy did not improve from 0.81597\n",
      "610/610 [==============================] - 526s 862ms/step - loss: 1.4904 - accuracy: 0.8559 - val_loss: 1.7119 - val_accuracy: 0.7181\n",
      "Epoch 5/10\n",
      "610/610 [==============================] - ETA: 0s - loss: 1.2468 - accuracy: 0.8835\n",
      "Epoch 5: val_accuracy did not improve from 0.81597\n",
      "610/610 [==============================] - 527s 864ms/step - loss: 1.2468 - accuracy: 0.8835 - val_loss: 1.5030 - val_accuracy: 0.7611\n",
      "Epoch 6/10\n",
      "610/610 [==============================] - ETA: 0s - loss: 1.0419 - accuracy: 0.9053\n",
      "Epoch 6: val_accuracy did not improve from 0.81597\n",
      "610/610 [==============================] - 527s 863ms/step - loss: 1.0419 - accuracy: 0.9053 - val_loss: 1.4964 - val_accuracy: 0.7590\n",
      "Epoch 7/10\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.8850 - accuracy: 0.9204\n",
      "Epoch 7: val_accuracy did not improve from 0.81597\n",
      "610/610 [==============================] - 527s 864ms/step - loss: 0.8850 - accuracy: 0.9204 - val_loss: 1.4513 - val_accuracy: 0.7451\n",
      "Epoch 8/10\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.7497 - accuracy: 0.9332\n",
      "Epoch 8: val_accuracy did not improve from 0.81597\n",
      "610/610 [==============================] - 526s 863ms/step - loss: 0.7497 - accuracy: 0.9332 - val_loss: 1.4002 - val_accuracy: 0.7188\n",
      "Epoch 9/10\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.6538 - accuracy: 0.9422\n",
      "Epoch 9: val_accuracy did not improve from 0.81597\n",
      "610/610 [==============================] - 526s 862ms/step - loss: 0.6538 - accuracy: 0.9422 - val_loss: 1.3175 - val_accuracy: 0.7382\n",
      "Epoch 10/10\n",
      "610/610 [==============================] - ETA: 0s - loss: 0.5772 - accuracy: 0.9457\n",
      "Epoch 10: val_accuracy did not improve from 0.81597\n",
      "610/610 [==============================] - 526s 862ms/step - loss: 0.5772 - accuracy: 0.9457 - val_loss: 1.3572 - val_accuracy: 0.7139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 17:09:53.497983: W tensorflow/core/util/tensor_slice_reader.cc:98] Could not open best_weights: FAILED_PRECONDITION: best_weights; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7fadd3e1a920>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# Define a checkpoint callback\n",
    "checkpoint_filepath = 'best_weights'\n",
    "model_checkpoint = ModelCheckpoint(checkpoint_filepath, save_best_only=True, monitor='val_accuracy', mode='max', save_format='tf', verbose=1)\n",
    "\n",
    "\n",
    "# X and label_train remain the same as in your code\n",
    "X = [input_ids_train_source,token_type_ids_train_source, attention_mask_train_source,input_ids_train_reply,token_type_ids_train_reply, attention_mask_train_reply,replicated_array_train]\n",
    "label_train = np.asarray(encoded_dataset_source['train'][\"label_number\"]).astype(np.float32)\n",
    "label_val = np.asarray(encoded_dataset_source['valid'][\"label_number\"]).astype(np.float32)\n",
    "\n",
    "# Train the modified model with the checkpoint callback\n",
    "history = modified_model.fit(X, label_train,\n",
    "                              validation_data=([input_ids_valid_source, token_type_ids_valid_source, attention_mask_valid_source,\n",
    "                                                input_ids_valid_reply, token_type_ids_valid_reply, attention_mask_valid_reply,\n",
    "                                                replicated_array_val], label_val),\n",
    "                              epochs=num_epochs, batch_size=8, callbacks=[model_checkpoint])\n",
    "\n",
    "# Load the best weights\n",
    "modified_model.load_weights(checkpoint_filepath)\n",
    "\n",
    "# Now you can use the modified_model for testing or further evaluation\n",
    "# modified_model.evaluate(test_data, test_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "hdEr-3uKswln"
   },
   "outputs": [],
   "source": [
    "replicated_array_test = np.tile(arr2, (len(encoded_dataset_reply[\"test\"]), 1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "QTB_3GIVSw9o"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 51s 874ms/step - loss: 2.2055 - accuracy: 0.8436\n",
      "Test Accuracy: 84.36%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test dataset\n",
    "#X_test = [input_ids_test_source,token_type_ids_test_source, attention_mask_test_source,input_ids_test_reply,token_type_ids_test_reply, attention_mask_test_reply,v_p_s_test,v_neg_s_test,v_neu_s_test,v_p_r_test,v_neg_r_test,v_neu_r_test,clip_s_test,clip_r_test,replicated_array_test]\n",
    "X_test = [input_ids_test_source,token_type_ids_test_source, attention_mask_test_source,input_ids_test_reply,token_type_ids_test_reply, attention_mask_test_reply,replicated_array_test]\n",
    "label_test = np.asarray(encoded_dataset_source['test'][\"label_number\"]).astype(np.float32)\n",
    "\n",
    "test_results = modified_model.evaluate(X_test,label_test)\n",
    "\n",
    "# Print the test accuracy\n",
    "test_accuracy = test_results[1] * 100\n",
    "print(\"Test Accuracy: {:.2f}%\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "ty6qW-n4eQ5J"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 52s 872ms/step\n",
      "F1 Score: 0.81\n",
      "F1 macro Score: {:.2f} (0.5597137263879143, 0.42025297804212397, 0.4388216327912988, None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_pred = modified_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "# Get the true labels from the test dataset\n",
    "# y_true = tf_test_dataset.map(lambda x, y: y)\n",
    "# y_true = np.concatenate(list(y_true.as_numpy_iterator()))\n",
    "\n",
    "# Calculate the F1 score\n",
    "f1score = f1_score(label_test, y_pred, average='weighted')\n",
    "f1_score_macro =precision_recall_fscore_support(label_test, y_pred, average='macro')\n",
    "\n",
    "print(\"F1 Score: {:.2f}\".format(f1score))\n",
    "print(\"F1 macro Score: {:.2f}\",(f1_score_macro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "id": "yht2ptVyeUm9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 46s 873ms/step\n",
      "F1 Score for label 0: 0.02\n",
      "F1 Score for label 1: 0.91\n",
      "F1 Score for label 2: 0.34\n",
      "F1 Score for label 3: 0.48\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "y_pred = modified_model.predict(X_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)  # Convert predicted probabilities to class labels\n",
    "\n",
    "# Get the true labels from the test dataset\n",
    "#y_true = tf_test_dataset.map(lambda x, y: y)\n",
    "#y_true = np.concatenate(list(y_true.as_numpy_iterator()))\n",
    "# Calculate the F1 score for each label\n",
    "y_true = label_test\n",
    "num_labels = 4 # Number of labels in the dataset\n",
    "f1_scores = []\n",
    "for label in range(num_labels):\n",
    "    label_true = (y_true == label)\n",
    "    label_pred = (y_pred == label)\n",
    "    label_f1_score = f1_score(label_true, label_pred)\n",
    "    f1_scores.append(label_f1_score)\n",
    "\n",
    "# Print the F1 score for each label\n",
    "for label, f1_score in enumerate(f1_scores):\n",
    "    print(\"F1 Score for label {}: {:.2f}\".format(label, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p-WnhJCV-xSR"
   },
   "outputs": [],
   "source": [
    "support 0.40 deny 0.55 comment 0.90 query 0.22 0.385 \n",
    "support 0.02 commnet 0.34 deny 0.91 query 0.48  \n",
    "'support': 0, 'comment': 1, 'deny': 2, 'query': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "daLvHzL8lq2m"
   },
   "outputs": [],
   "source": [
    "modified_model.save(\"lata\", save_format=\"tf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kg13GH2gme1u"
   },
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "\n",
    "# # Load the model\n",
    "# loaded_model = load_model(\"lata\")\n",
    "\n",
    "# # Now you can use the loaded_model for inference without retraining\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "RDLe_DB8miCj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 [==============================] - 46s 863ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions=modified_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "_xFWuMT2m2wx"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0808573 , 0.8156917 , 0.07039624, 0.03305472],\n",
       "       [0.16664861, 0.7586253 , 0.04977947, 0.02494655],\n",
       "       [0.12760513, 0.55149883, 0.09476161, 0.22613445],\n",
       "       ...,\n",
       "       [0.07732699, 0.843201  , 0.05615843, 0.02331355],\n",
       "       [0.06859208, 0.8379199 , 0.06497687, 0.02851118],\n",
       "       [0.05840518, 0.86761695, 0.04689997, 0.02707791]], dtype=float32)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "id": "JMRlXD-voPwK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8435820895522388\n",
      "Precision: 0.7977051079568231\n",
      "Recall: 0.8435820895522388\n",
      "F1-Score: 0.8061053436100679\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# Assuming y_true and y_pred are NumPy arrays\n",
    "# If they are not NumPy arrays, you can convert them using np.array(your_list)\n",
    "\n",
    "# Example true labels (ground truth) for a multiclass problem\n",
    "y_true = np.array(label_test)\n",
    "\n",
    "# Example predicted probabilities from your model\n",
    "# This assumes you have a model predicting probabilities for each class\n",
    "y_probs = np.array(predictions)\n",
    "\n",
    "# Convert predicted probabilities to class labels\n",
    "y_pred = np.argmax(y_probs, axis=-1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f'Accuracy: {accuracy}')\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision = precision_score(y_true, y_pred, average='weighted')\n",
    "recall = recall_score(y_true, y_pred, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "5j8HBNDVpBuf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics saved to metrics.txt\n"
     ]
    }
   ],
   "source": [
    "with open(\"metrics.txt\", \"w\") as file:\n",
    "    file.write(f'Accuracy: {accuracy}\\n')\n",
    "    file.write(f'Precision: {precision}\\n')\n",
    "    file.write(f'Recall: {recall}\\n')\n",
    "    file.write(f'F1-Score: {f1}\\n')\n",
    "\n",
    "print(\"Metrics saved to metrics.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "051e5e2ec40d4c3ab009fb2e61ea5ec7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "097faca8be3d4093979bc101c32b89bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_051e5e2ec40d4c3ab009fb2e61ea5ec7",
      "placeholder": "​",
      "style": "IPY_MODEL_f0834e5d3d154491991fdf111a8e1604",
      "value": "vocab.txt: 100%"
     }
    },
    "0b33790c443843d3a7cfa8b1220079fa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0d3799346117440c817127a69bdb2936": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a5bc1bbbde9f456a98ae94fe2e0f2419",
       "IPY_MODEL_d81035761da64e28a76ba4957a86fbe6",
       "IPY_MODEL_a2643e24790149e1a4d72b45f894b60a"
      ],
      "layout": "IPY_MODEL_388cdfe2d0b24536a8d9f7ca59753212"
     }
    },
    "11a2cc19ff384a8eaaa5082416320f16": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_95b9b970b3af4498b98aafa105fe38e1",
      "placeholder": "​",
      "style": "IPY_MODEL_801b972f226f4c71a1fbbb67f728e5b2",
      "value": " 1675/1675 [00:00&lt;00:00, 2269.41 examples/s]"
     }
    },
    "122003800fb5489c81836e893dac45b9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1277ea9e402e4770a37a811bbca55487",
      "placeholder": "​",
      "style": "IPY_MODEL_7c73d698e09d4887a896dd5f5b89ccf2",
      "value": "Map: 100%"
     }
    },
    "1277ea9e402e4770a37a811bbca55487": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "14bd9bc013a7439594ab3720f7d28eaf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "17f29d7a39a24fe8aacc5f73ca12dc32": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "19af24aa67a14504b58640d9a8521db3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96c7e2ba96364cd6ab917102f94d0a72",
      "placeholder": "​",
      "style": "IPY_MODEL_5d6387a0bc574ac893df523b80e28736",
      "value": "model.safetensors: 100%"
     }
    },
    "255561010d8245ee93903706ade19da7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "266e992726d64d29b880a4d2d7b5f4fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "26a65d266b234077bcda7400cb34431a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2c164843ef0f492e9ef62734d84d6b1f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a46d93c247284282a2b39ada9bbe604c",
      "max": 570,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e401c1e3a85b428cabe2a5d90842fdb8",
      "value": 570
     }
    },
    "2e4000e7d1fe4832b3f816879544abbc": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2eb155c62de44794ac01bfa0696a9796": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_14bd9bc013a7439594ab3720f7d28eaf",
      "max": 1675,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d4d8bd4be3304bb9bce2738bb93fdc17",
      "value": 1675
     }
    },
    "388cdfe2d0b24536a8d9f7ca59753212": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3f9462352e9d418897d2661978c06a2c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_097faca8be3d4093979bc101c32b89bc",
       "IPY_MODEL_83ac50d258e54371a5d1fcd55cd3168c",
       "IPY_MODEL_4ecb9ee623a5424abccb2d91f8e065d7"
      ],
      "layout": "IPY_MODEL_7ce14c02563d4b8185a4fa2cd18244f4"
     }
    },
    "40e9ce82eff94521a5ce93050acf68fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8f7c1364418e40b69d67b36d14e5bbd1",
      "placeholder": "​",
      "style": "IPY_MODEL_b7c369b70ed84a24bc88ede97844defc",
      "value": " 436M/436M [00:06&lt;00:00, 74.1MB/s]"
     }
    },
    "43eaf6c6d2dc481c9f54a8e00b3822c9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_122003800fb5489c81836e893dac45b9",
       "IPY_MODEL_2eb155c62de44794ac01bfa0696a9796",
       "IPY_MODEL_11a2cc19ff384a8eaaa5082416320f16"
      ],
      "layout": "IPY_MODEL_d2b7d1759e35498c880756cf937102ed"
     }
    },
    "4442d8fb3fba4e10a92a190208a6027c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4dbec91e4544476cae6edc0feea56dd6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ecb9ee623a5424abccb2d91f8e065d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_255561010d8245ee93903706ade19da7",
      "placeholder": "​",
      "style": "IPY_MODEL_a2a778cc97874b9eb021b4d0eaca2e2a",
      "value": " 213k/213k [00:00&lt;00:00, 548kB/s]"
     }
    },
    "58ab2086ba0d40f68a63bedb118fd5b3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5babae87e56843bcb998c1d9d1014a4a",
      "max": 435755784,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_17f29d7a39a24fe8aacc5f73ca12dc32",
      "value": 435755784
     }
    },
    "5a8df37110d741b8b6ac3e8e4acf9209": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5babae87e56843bcb998c1d9d1014a4a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c19b855bdaf4307bad8f1c8126e6c9e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5c99477e24d749a09dec6f39cc4bb851": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7f0caff662b4046b0b4c7ce90cf6522",
      "max": 498818054,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9141467ff832403e98ea2d1dde434b77",
      "value": 498818054
     }
    },
    "5d6387a0bc574ac893df523b80e28736": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5f047266bcdf4a41bd6f3fe80cb38e03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a08f13ebd4064db99cccebf69a5550bf",
      "max": 29,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5a8df37110d741b8b6ac3e8e4acf9209",
      "value": 29
     }
    },
    "672eea6acc894fec9efb55efb0ad421e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b33790c443843d3a7cfa8b1220079fa",
      "placeholder": "​",
      "style": "IPY_MODEL_9200e4dcf2af493d96c8f4e3ef9dc9ec",
      "value": " 499M/499M [00:07&lt;00:00, 68.4MB/s]"
     }
    },
    "77baa7033ec24055a0ba7e04efaa7e6f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7c70afbbff044df491df36f19d9a0970": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e4000e7d1fe4832b3f816879544abbc",
      "placeholder": "​",
      "style": "IPY_MODEL_9bc832bc4eb4403a9825ec941f6e9b9d",
      "value": " 570/570 [00:00&lt;00:00, 10.2kB/s]"
     }
    },
    "7c73d698e09d4887a896dd5f5b89ccf2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7ce14c02563d4b8185a4fa2cd18244f4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ece26d808584dc8991a0f35e649da87": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "801b972f226f4c71a1fbbb67f728e5b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "804ee798e26b4570b5a153dae816cbe3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c537e6910b3540558e9f6c376be65d8c",
      "placeholder": "​",
      "style": "IPY_MODEL_b2c7ca98624e48de8e8210efc899ac1a",
      "value": "model.safetensors: 100%"
     }
    },
    "83ac50d258e54371a5d1fcd55cd3168c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_994b011d50ea4bbfb0e8edade091a328",
      "max": 213450,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9ec255222851461789a192ae3416c845",
      "value": 213450
     }
    },
    "8b20937252034cd3a4a1c2685af9bda3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f26974f197a44d688143dd71eb1019e3",
       "IPY_MODEL_2c164843ef0f492e9ef62734d84d6b1f",
       "IPY_MODEL_7c70afbbff044df491df36f19d9a0970"
      ],
      "layout": "IPY_MODEL_9ae54140172d4182bc877725f78e9d64"
     }
    },
    "8d7d6dbad25e4df7ab94f446b46307d2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d7e447b410ee47fea591122ff2d0c497",
       "IPY_MODEL_5f047266bcdf4a41bd6f3fe80cb38e03",
       "IPY_MODEL_c9d091cea7e84b7091373468dfa654ed"
      ],
      "layout": "IPY_MODEL_26a65d266b234077bcda7400cb34431a"
     }
    },
    "8f7c1364418e40b69d67b36d14e5bbd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "902f7898eb4b4feb99714a1e49fa070a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9141467ff832403e98ea2d1dde434b77": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9200e4dcf2af493d96c8f4e3ef9dc9ec": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "95b9b970b3af4498b98aafa105fe38e1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96c7e2ba96364cd6ab917102f94d0a72": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "96e74621c130478c9e4641ee4a6c14d5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "994b011d50ea4bbfb0e8edade091a328": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9ae54140172d4182bc877725f78e9d64": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9bc832bc4eb4403a9825ec941f6e9b9d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9ec255222851461789a192ae3416c845": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a08f13ebd4064db99cccebf69a5550bf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a2643e24790149e1a4d72b45f894b60a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4dbec91e4544476cae6edc0feea56dd6",
      "placeholder": "​",
      "style": "IPY_MODEL_e1d5bd15188f4cd7a324dd41dc55300e",
      "value": " 436k/436k [00:00&lt;00:00, 2.22MB/s]"
     }
    },
    "a2a778cc97874b9eb021b4d0eaca2e2a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a46d93c247284282a2b39ada9bbe604c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a5bc1bbbde9f456a98ae94fe2e0f2419": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed95b9e3da6f4a6cb2e7292ecb1267f1",
      "placeholder": "​",
      "style": "IPY_MODEL_d0077d9fc8434bdf9fbf4d5b6e206bf7",
      "value": "tokenizer.json: 100%"
     }
    },
    "b2c7ca98624e48de8e8210efc899ac1a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b7c369b70ed84a24bc88ede97844defc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c537e6910b3540558e9f6c376be65d8c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9d091cea7e84b7091373468dfa654ed": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e190ffa64ee842f08272e2ed22f39611",
      "placeholder": "​",
      "style": "IPY_MODEL_902f7898eb4b4feb99714a1e49fa070a",
      "value": " 29.0/29.0 [00:00&lt;00:00, 969B/s]"
     }
    },
    "d0077d9fc8434bdf9fbf4d5b6e206bf7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2b7d1759e35498c880756cf937102ed": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d2f37583aea94993bd44ebb914310aa1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_19af24aa67a14504b58640d9a8521db3",
       "IPY_MODEL_58ab2086ba0d40f68a63bedb118fd5b3",
       "IPY_MODEL_40e9ce82eff94521a5ce93050acf68fa"
      ],
      "layout": "IPY_MODEL_e833704b51464864a1f316ed1e7a8212"
     }
    },
    "d4d8bd4be3304bb9bce2738bb93fdc17": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d7e447b410ee47fea591122ff2d0c497": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_96e74621c130478c9e4641ee4a6c14d5",
      "placeholder": "​",
      "style": "IPY_MODEL_4442d8fb3fba4e10a92a190208a6027c",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "d81035761da64e28a76ba4957a86fbe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fb818641fd6a4c63920b9431fd29dac5",
      "max": 435797,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_77baa7033ec24055a0ba7e04efaa7e6f",
      "value": 435797
     }
    },
    "e190ffa64ee842f08272e2ed22f39611": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e1d5bd15188f4cd7a324dd41dc55300e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e401c1e3a85b428cabe2a5d90842fdb8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e833704b51464864a1f316ed1e7a8212": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ed95b9e3da6f4a6cb2e7292ecb1267f1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f0834e5d3d154491991fdf111a8e1604": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f26974f197a44d688143dd71eb1019e3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5c19b855bdaf4307bad8f1c8126e6c9e",
      "placeholder": "​",
      "style": "IPY_MODEL_266e992726d64d29b880a4d2d7b5f4fc",
      "value": "config.json: 100%"
     }
    },
    "f7f0caff662b4046b0b4c7ce90cf6522": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f8053bbfdf8342efaed9c8b7c3d12a79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_804ee798e26b4570b5a153dae816cbe3",
       "IPY_MODEL_5c99477e24d749a09dec6f39cc4bb851",
       "IPY_MODEL_672eea6acc894fec9efb55efb0ad421e"
      ],
      "layout": "IPY_MODEL_7ece26d808584dc8991a0f35e649da87"
     }
    },
    "fb818641fd6a4c63920b9431fd29dac5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
